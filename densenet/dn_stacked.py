# -*- coding: utf-8 -*-
"""DC_histopathology_capsule.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Xw5Qs2ldxgB3-8s9h2bWQtuZ2-aaXgP3

run-2
"""

# from google.colab import drive
# drive.mount('/content/drive')

"""## Introduction


"""

import os
import numpy as np



import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers


path = "/workspace/storage"
# path = ".."

FA_nodule=os.listdir(path+"/content/FA_nodule")
print("Total images in FA_capsule ",len(FA_nodule))
NIFTP_nodule=os.listdir(path+"/content/NIFTP nodule")
print("Total images in NIFTP_capsule ",len(NIFTP_nodule))
PTC_nodule=os.listdir(path+"/content/PTC_nodule")
print("Total images in PTC_capsule ",len(PTC_nodule))

FA_capsule=os.listdir(path+"/content/FA_capsule")
print("Total images in FA_capsule ",len(FA_capsule))
NIFTP_capsule=os.listdir(path+"/content/NIFTP capsule")
print("Total images in NIFTP_capsule ",len(NIFTP_capsule))
PTC_capsule=os.listdir(path+"/content/PTC_capsule")
print("Total images in PTC_capsule ",len(PTC_capsule))

print('hi')

patient_all_dir = []
patient_fanod=[]
patient_facap=[]
patient_niftpnod=[]
patient_niftpcap=[]
patient_ptcnod=[]
patient_ptccap=[]
patient_fa=[]
patient_niftp=[]
patient_ptc=[]
patient_dir=[]
patient_dict={}

for dir in FA_nodule:
    patient_id=dir.split("_")[0]
    if patient_id not in patient_fanod:
      patient_fanod.append(dir.split("_")[0])


for dir in FA_capsule:
    patient_id=dir.split("_")[0]
    if patient_id not in patient_facap:
      patient_facap.append(patient_id)
    if patient_id in patient_fanod:
      if patient_id not in patient_fa:
        patient_fa.append(patient_id)
        patient_dict[patient_id]=0




for dir in NIFTP_capsule:
    patient_id=dir.split("_")[0]
    if patient_id not in patient_niftpcap:
      patient_niftpcap.append(patient_id)




for dir in NIFTP_nodule:
    patient_id=dir.split("_")[0]
    if patient_id not in patient_niftpnod:
      patient_niftpnod.append(patient_id)
    if patient_id in patient_niftpcap:
      if patient_id not in patient_niftp:
        patient_niftp.append(patient_id)
        patient_dict[patient_id]=1



for dir in PTC_capsule:
    patient_id=dir.split("_")[0]
    if patient_id not in patient_ptccap:
      patient_ptccap.append(patient_id)



for dir in PTC_nodule:
    patient_id=dir.split("_")[0]
    if patient_id not in patient_ptcnod:
      patient_ptcnod.append(patient_id)
    if patient_id in patient_ptccap:
      if patient_id not in patient_ptc:
        patient_ptc.append(patient_id)
        patient_dict[patient_id]=2



patient_dir=patient_fa+patient_niftp+patient_ptc
print("Total unique patient ID of FACAP : ", len(np.unique(patient_facap)))
print("Total unique patient ID of FANOD : ", len(np.unique(patient_fanod)))
print("Total unique patient ID of NIFTPCAP : ", len(np.unique(patient_niftpcap)))
print("Total unique patient ID of NOFTPNOD : ", len(np.unique(patient_niftpnod)))
print("Total unique patient ID of PTCCAP : ", len(np.unique(patient_ptccap)))
print("Total unique patient ID of PTCNOD : ", len(np.unique(patient_ptcnod)))
print("Total unique patient ID of NIFTP : ", len(np.unique(patient_niftp)))
print("Total unique patient ID of PTC: ", len(np.unique(patient_ptc)))
print("Total unique patient ID of FA : ", len(np.unique(patient_fa)))



from collections import Counter
common_ids=[(item,count) for item, count in Counter(patient_dir).items() if count > 1]

for item in common_ids:
  for i in range(item[1]):
    patient_dir.remove(item[0])

len_patient=len(patient_dir)
print(len_patient)

# print("Training set will contain dataset of ", int(0.8*56)," patients")

len_train=int(0.7*len_patient)
len_val=int(0.1*len_patient)
len_test=len(patient_dir)-(len_train+len_val)
print("Training set will contain dataset of ", int(len_train)," patients")
print("Validation set will contain dataset of ", int(len_val)," patients")
print("Testing set will contain dataset of ", int(len_test)," patients")
# import random
# train_id = random.sample(patient_dir, 44)

import random
print(len_train+len_val)
patient_dir=np.array(patient_dir)
print(len(patient_dir))

while True:
  test_id = np.random.choice(patient_dir, size=len_test, replace=False)
  train_id=np.setdiff1d(patient_dir,test_id)

  if len(np.intersect1d(train_id,patient_fa))>0 and len(np.intersect1d(train_id,patient_niftp))>0 and len(np.intersect1d(train_id, patient_ptc))>0 and len(np.intersect1d(test_id,patient_fa))>0 and len(np.intersect1d(test_id,patient_niftp))>0 and len(np.intersect1d(test_id, patient_ptc))>0:
    
    break

while True:
  val_id= np.random.choice(train_id, size=len_val, replace=False)
  train_id=np.setdiff1d(train_id, val_id)
  if len(np.intersect1d(train_id,patient_fa))>0 and len(np.intersect1d(train_id,patient_niftp))>0 and len(np.intersect1d(train_id, patient_ptc))>0 and len(np.intersect1d(val_id,patient_fa))>0 and len(np.intersect1d(val_id,patient_niftp))>0 and len(np.intersect1d(val_id, patient_ptc))>0:

    break
  else:
     train_id = np.append(train_id, val_id)

print(train_id, len(train_id), val_id, len(val_id), test_id, len(test_id))

results_dict={}
results_dict['training_patient_ids']=str(train_id.tolist())
results_dict['validation_patient_ids']=str(val_id.tolist())
results_dict['testing_patient_ids']=str(test_id.tolist())
# print(FAC_nodule[0])

import glob
fanod = glob.glob('/content/FA nodule*.*')
facap = glob.glob('/content/FA_capsule*.*')
niftpcap = glob.glob('/content/NIFTP capsule*.*')
niftpnod = glob.glob('/content/NIFTP nodule*.*')
ptccap = glob.glob('/content/PTC capsule*.*')
ptcnod = glob.glob('/content/PTC_nodule*.*')

X_train=[]
X_val=[]
X_test=[]
ytrain=[]
yval=[]
ytest=[]
lst=[]

roi_combination_train=[]
roi_combination_val=[]
roi_combination_test=[]

for i in FA_capsule:
  k=i.split("_")[0]
  for j in FA_nodule:
    if k in j:
      image1=tf.keras.preprocessing.image.load_img(path+"/content/FA_nodule/"+j, color_mode='rgb', target_size= (224,224))
      image2=tf.keras.preprocessing.image.load_img(path+"/content/FA_capsule/"+i, color_mode='rgb', target_size= (224,224))
      image1=np.array(image1)
      image2=np.array(image2)
      image= tf.concat([image1,image2],axis=-1)

      image=np.array(image)
      if k in train_id:
        X_train.append(image)
        ytrain.append(0)
      elif k in val_id:
        X_val.append(image)
        yval.append(0)
      else:
        X_test.append(image)
        ytest.append(0)


for i in NIFTP_capsule:
  k=i.split("_")[0]
  for j in NIFTP_nodule:
    if k in j:
      image1=tf.keras.preprocessing.image.load_img(path+"/content/NIFTP nodule/"+j, color_mode='rgb', target_size= (224,224))
      image2=tf.keras.preprocessing.image.load_img(path+"/content/NIFTP capsule/"+i, color_mode='rgb', target_size= (224,224))
      image1=np.array(image1)
      image2=np.array(image2)
      image= tf.concat([image1,image2],axis=-1)

      image=np.array(image)
      if k in train_id:
        X_train.append(image)
        ytrain.append(1)
      elif k in val_id:
        X_val.append(image)
        yval.append(1)
      else:
        X_test.append(image)
        ytest.append(1)

for i in PTC_capsule:
  k=i.split("_0")[0]
  for j in PTC_nodule:
    if k in j:
      image1=tf.keras.preprocessing.image.load_img(path+"/content/PTC_nodule/"+j, color_mode='rgb', target_size= (224,224))
      image2=tf.keras.preprocessing.image.load_img(path+"/content/PTC_capsule/"+i, color_mode='rgb', target_size= (224,224))
      image1=np.array(image1)
      image2=np.array(image2)
      image= tf.concat([image1,image2],axis=-1)

      image=np.array(image)
      if i.split("_")[0] in train_id:
        X_train.append(image)
        ytrain.append(2)
      elif k in val_id:
        X_val.append(image)
        yval.append(2)
      else:
        X_test.append(image)
        ytest.append(2)


X_train=np.array(X_train)
X_val=np.array(X_val)
X_test=np.array(X_test)

ytrain=np.array(ytrain)
yval=np.array(yval)
ytest=np.array(ytest)

print(ytrain)
print(yval)
print(ytest)


print('X_train shape',X_train.shape)
print('X_val shape',X_val.shape)
print('X_test shape',X_test.shape)
print('ytrain shape',ytrain.shape)
print('yval shape',yval.shape)
print('ytest shape',ytest.shape)


#shuffling the data
# shuffler_train=np.random.permutation(X_train.shape[0])
# shuffler_val=np.random.permutation(X_val.shape[0])
# shuffler_test=np.random.permutation(X_test.shape[0])
# X_train=X_train[shuffler_train]
# X_val=X_val[shuffler_val]
# X_test=X_test[shuffler_test]
# ytrain=ytrain[shuffler_train]
# yval=yval[shuffler_val]
# ytest=ytest[shuffler_test]

print(X_train.shape)
print(X_val.shape)
print(X_test.shape)
print(ytrain.shape)
print(yval.shape)
print(ytest.shape)


"""## Setup

## Prepare the data
"""

num_classes = 3
input_shape = (224, 224, 6)

"""## Configure the hyperparameters"""

learning_rate = 0.001 
weight_decay = 0.0001 
batch_size = 128 
num_epochs = 100 
image_size = 224  # We'll resize input images to this size
  # Size of the patches to be extract from the input images
  # Size of the dense layers of the final classifier

"""## Use data augmentation"""

data_augmentation = keras.Sequential(
    [
        # layers.Resizing(image_size, image_size),
        layers.RandomFlip("horizontal"),
        layers.RandomRotation(factor=0.02),
        layers.RandomZoom(
            height_factor=0.2, width_factor=0.2
        ),
    ],
    name="data_augmentation",
)
# Compute the mean and the variance of the training data for normalization.

X_train = tf.convert_to_tensor(X_train)
ytrain = tf.convert_to_tensor(ytrain)
X_train = data_augmentation(X_train)

import tensorflow as tf
from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Dense
from tensorflow.keras.layers import AvgPool2D, GlobalAveragePooling2D, MaxPool2D
from tensorflow.keras.models import Model
from tensorflow.keras.layers import ReLU, concatenate
import tensorflow.keras.backend as K
# Creating Densenet121
def densenet(input_shape, n_classes, filters = 32):

    #batch norm + relu + conv
    def bn_rl_conv(x,filters,kernel=1,strides=1):

        x = BatchNormalization()(x)
        x = ReLU()(x)
        x = Conv2D(filters, kernel, strides=strides,padding = 'same')(x)
        return x

    def dense_block(x, repetition):

        for _ in range(repetition):
            y = bn_rl_conv(x, 4*filters)
            y = bn_rl_conv(y, filters, 3)
            x = concatenate([y,x])
        return x

    def transition_layer(x):
        x = bn_rl_conv(x, K.int_shape(x)[-1] //2 )
        x = AvgPool2D(2, strides = 2, padding = 'same')(x)
        return x

    input = Input (input_shape)
    x = Conv2D(64, 7, strides = 2, padding = 'same')(input)
    x = MaxPool2D(3, strides = 2, padding = 'same')(x)

    for repetition in [6,12,24,16]:
        d = dense_block(x, repetition)
        x = transition_layer(d)

    x = GlobalAveragePooling2D()(d)
    output = Dense(n_classes, activation = 'softmax')(x)

    model = Model(input, output)
    return model
input_shape = 224, 224, 6
n_classes = 3
# model = densenet(input_shape,n_classes)
# model.summary()

"""## Compile, train, and evaluate the mode"""

def run_experiment(model):
    optimizer = tf.keras.optimizers.Adam(
        learning_rate=learning_rate, decay=weight_decay
    )

    model.compile(
        optimizer=optimizer,
        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),
        metrics=[
            keras.metrics.SparseCategoricalAccuracy(name="accuracy"),
        ],
    )
    # model.compile(loss='categorical_crossentropy',
    #           optimizer=optimizer,
    #           metrics=['accuracy'])

    # tuner = kt.Hyperband(create_vit_classifier,
    #                      objective='val_accuracy',
    #                      max_epochs=10,
    #                      factor=3,
    #                      )
    # earlystop_callback= keras.callbacks.EarlyStopping(
    #     monitor='val_accuracy',
    #     min_delta=0.001,
    #     patience=3,
    #     verbose=1,
    # )

    checkpoint_filepath = "/tmp/checkpoint"
    checkpoint_callback = keras.callbacks.ModelCheckpoint(
        checkpoint_filepath,
        monitor="val_accuracy",
        save_best_only=True,
        save_weights_only=True,
    )

    # tuner.search(X_train, ytrain, epochs=100, batch_size=batch_size, validation_data=(X_val, yval), callbacks=[checkpoint_callback, earlystop_callback])

    # Get the optimal hyperparameters
    # best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]
    # print(best_hps)
    # print("hello")

    # model = tuner.hypermodel.build(best_hps)

    history = model.fit(
        x=X_train,
        y=ytrain,
        batch_size=batch_size,
        epochs=100,
        validation_data=(X_val, yval),
        callbacks=[checkpoint_callback],
    )

    model.load_weights(checkpoint_filepath)
    _, accuracy = model.evaluate(X_test, ytest)
    yt=model.predict(X_test)


    pred=[]
    for i in range(len(yt)):
        d=np.where(yt[i]==max(yt[i]))
        pred.append(d[0][0])
    print(f"Test accuracy: {round(accuracy * 100, 2)}%")
    # print(f"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%")

    return history,pred,yt

# ds = tf.keras.applications.densenet.DenseNet121(
#     include_top=True,
#     weights='imagenet',
#     input_tensor= tf.convert_to_tensor(X_train),
#     input_shape=(224,224,3),
#     pooling=None,
#     classes=1000,
#     classifier_activation='softmax'
# )
ds_classifier = densenet(input_shape,n_classes)


history,pred,prob = run_experiment(ds_classifier)
print(history.history.keys())

pred

ytest

prob.shape

acc=0
for i in range(len(pred)):
  if (pred[i]==ytest[i]):
    acc+=1
print(acc/len(pred)*100)

import matplotlib.pyplot as plt
from datetime import datetime

now= datetime.now()
dt_string = now.strftime("%d_%m_%Y %H_%M_%S")

print(history.history.keys())
# summarize history for accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
# plt.show()
plt.savefig('/workspace/storage/results/densenet/'+dt_string+' stacked_accuracy')
plt.show()
# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
# plt.show()
plt.savefig('/workspace/storage/results/densenet/'+dt_string+' stacked_loss')
plt.show()

"""seeding , au roc class wise, try other transformer deit recent ones, con next, common patient , VIT large, diff hyperpara , 217A,"""

from sklearn.metrics import classification_report
target_names = ['FA', 'NIFTP', 'PTC']
metric_report=classification_report(ytest, pred, target_names=target_names, output_dict=True)
print(classification_report(ytest, pred, target_names=target_names))

results_dict['Class-wise Precision']="FA - "+str(metric_report['FA']['precision'])+", "+"NIFTP - "+str(metric_report['NIFTP']['precision'])+", "+"PTC - "+str(metric_report['PTC']['precision'])+", "
results_dict['Macro-averaged Precision']=str(metric_report['macro avg']['precision'])
results_dict['Weighted-averaged Precision']=str(metric_report['weighted avg']['precision'])

results_dict['Class-wise recall']="FA - "+str(metric_report['FA']['recall'])+", "+"NIFTP - "+str(metric_report['NIFTP']['recall'])+", "+"PTC - "+str(metric_report['PTC']['recall'])+", "
results_dict['Macro-averaged recall']=str(metric_report['macro avg']['recall'])
results_dict['Weighted-averaged recall']=str(metric_report['weighted avg']['recall'])

results_dict['Class-wise f1-score']="FA - "+str(metric_report['FA']['f1-score'])+", "+"NIFTP - "+str(metric_report['NIFTP']['f1-score'])+", "+"PTC - "+str(metric_report['PTC']['f1-score'])+", "
results_dict['Macro-averaged f1-score']=str(metric_report['macro avg']['f1-score'])
results_dict['Weighted-averaged f1-score']=str(metric_report['weighted avg']['f1-score'])

print(results_dict)

from sklearn.metrics import confusion_matrix
model_conf = confusion_matrix(ytest, pred)
print(model_conf)

X_test.shape

X_test2=X_test

import pandas as pd
df = pd.DataFrame(X_test2.tolist())

df

import seaborn as sns
from sklearn.metrics import roc_auc_score
def calculate_tpr_fpr(y_real, y_pred):
    '''
    Calculates the True Positive Rate (tpr) and the True Negative Rate (fpr) based on real and predicted observations

    Args:
        y_real: The list or series with the real classes
        y_pred: The list or series with the predicted classes

    Returns:
        tpr: The True Positive Rate of the classifier
        fpr: The False Positive Rate of the classifier
    '''

    # Calculates the confusion matrix and recover each element
    cm = confusion_matrix(y_real, y_pred)
    TN = cm[0, 0]
    FP = cm[0, 1]
    FN = cm[1, 0]
    TP = cm[1, 1]

    # Calculates tpr and fpr
    tpr =  TP/(TP + FN) # sensitivity - true positive rate
    fpr = 1 - TN/(TN+FP) # 1-specificity - false positive rate

    return tpr, fpr

def get_all_roc_coordinates(y_real, y_proba):
    '''
    Calculates all the ROC Curve coordinates (tpr and fpr) by considering each point as a threshold for the predicion of the class.

    Args:
        y_real: The list or series with the real classes.
        y_proba: The array with the probabilities for each class, obtained by using the `.predict_proba()` method.

    Returns:
        tpr_list: The list of TPRs representing each threshold.
        fpr_list: The list of FPRs representing each threshold.
    '''
    tpr_list = [0]
    fpr_list = [0]
    for i in range(len(y_proba)):
        threshold = y_proba[i]
        y_pred = y_proba >= threshold
        tpr, fpr = calculate_tpr_fpr(y_real, y_pred)
        tpr_list.append(tpr)
        fpr_list.append(fpr)
    return tpr_list, fpr_list


def plot_roc_curve(tpr, fpr, scatter = True, ax = None):
    '''
    Plots the ROC Curve by using the list of coordinates (tpr and fpr).

    Args:
        tpr: The list of TPRs representing each coordinate.
        fpr: The list of FPRs representing each coordinate.
        scatter: When True, the points used on the calculation will be plotted with the line (default = True).
    '''
    # if ax == None:
    #     plt.figure(figsize = (5, 5))
    #     ax = plt.axes()

    # if scatter:
    #     sns.scatterplot(x = fpr, y = tpr, ax = ax)
    # sns.lineplot(x = fpr, y = tpr, ax = ax)
    # sns.lineplot(x = [0, 1], y = [0, 1], color = 'green', ax = ax)
    # plt.xlim(-0.05, 1.05)
    # plt.ylim(-0.05, 1.05)
    # plt.xlabel("False Positive Rate")
    # plt.ylabel("True Positive Rate")

# plt.figure(figsize = (12, 8))
bins = [i/20 for i in range(20)] + [1]
classes = [0,1,2]
roc_auc_ovr = {}
for i in range(len(classes)):
    # Gets the class
    c = classes[i]

    # Prepares an auxiliar dataframe to help with the plots
    df_aux = df.copy()
    # df={}
    # print(classes[i],ytest[0])
    df_aux['class'] = [1 if y == c else 0 for y in ytest]
    df_aux['prob'] = prob[:, i]
    df_aux = df_aux.reset_index(drop = True)

    # Plots the probability distribution for the class and the rest
    # ax = plt.subplot(2, 3, i+1)
    # sns.histplot(x = "prob", data = df_aux, hue = 'class', color = 'b', ax = ax, bins = bins)
    # ax.set_title(c)
    # ax.legend([f"Class: {c}", "Rest"])
    # ax.set_xlabel(f"P(x = {c})")

    # Calculates the ROC Coordinates and plots the ROC Curves
    # ax_bottom = plt.subplot(2, 3, i+4)
    tpr, fpr = get_all_roc_coordinates(df_aux['class'], df_aux['prob'])
    # plot_roc_curve(tpr, fpr, scatter = False)a
    # ax_bottom.set_title("ROC Curve OvR")

    # Calculates the ROC AUC OvR
    roc_auc_ovr[c] = roc_auc_score(df_aux['class'], df_aux['prob'])
plt.tight_layout()

# Displays the ROC AUC for each class
avg_roc_auc = 0
i = 0
class_dict={0:'FA',1:'NIFTP', 2:'PTC'}
roc_auc_str=''
for k in roc_auc_ovr:
    avg_roc_auc += roc_auc_ovr[k]
    i += 1
    print(f"{k} ROC AUC OvR: {roc_auc_ovr[k]:.4f}")
    roc_auc_str=roc_auc_str+class_dict[k]+' - '+f"{roc_auc_ovr[k]:.4f}"+"  "

results_dict['Class-wise ROC_AUC score']=roc_auc_str
print(f"average ROC AUC OvR: {avg_roc_auc/i:.4f}")
results_dict['Average ROC_AUC score']=f"{avg_roc_auc/i:.4f}"
print(results_dict)

macro_roc_auc_func = roc_auc_score(ytest, prob, labels = classes, multi_class = 'ovr', average = 'macro')
print('macro average roc_auc score from function - ', macro_roc_auc_func)
weighted_roc_auc_func = roc_auc_score(ytest, prob, labels = classes, multi_class = 'ovr', average = 'weighted')
print('weighted average roc_auc score from function - ', weighted_roc_auc_func)
macro_ovo_roc_auc_func = roc_auc_score(ytest, prob, labels = classes, multi_class = 'ovo', average = 'macro')
print('macro average ovo roc_auc score from function - ', macro_ovo_roc_auc_func)
weighted_ovo_roc_auc_func = roc_auc_score(ytest, prob, labels = classes, multi_class = 'ovo', average = 'weighted')
print('weighted average ovo roc_auc score from function - ', weighted_ovo_roc_auc_func)

results_dict['Macro Average ROC_AUC score'] = macro_roc_auc_func
results_dict['Weighted Average ROC_AUC score'] = weighted_roc_auc_func
results_dict['Macro Average ovo ROC_AUC score'] = macro_roc_auc_func
results_dict['Weighted Average ovo ROC_AUC score'] = weighted_roc_auc_func


prob.shape

# Compares with sklearn (average only)
# "Macro" average = unweighted mean
# roc_auc_score(ytest, prob, labels = classes, multi_class = 'ovr', average = 'macro')

myArray = prob

#Transform data
normalizedArray = []

for row in range(0, len(myArray)):
    list = []
    Min =  min(myArray[row])
    Max = max(myArray[row])

    for element in myArray[row]:
        list.append(  float(element-Min)/float(Max- Min) )

    normalizedArray.append(list)

#Normalize to 1
newArray = []

for row in range(0, len(normalizedArray)):
    list = [x / sum(normalizedArray[row]) for x in normalizedArray[row]]
    newArray.append(list)

newArray



# Compares with sklearn (average only)
# "Macro" average = unweighted mean

roc_auc_score(ytest, newArray, labels = classes, multi_class = 'ovr', average = 'macro')

import seaborn as sns
from sklearn.metrics import roc_auc_score
def calculate_tpr_fpr(y_real, y_pred):
    '''
    Calculates the True Positive Rate (tpr) and the True Negative Rate (fpr) based on real and predicted observations

    Args:
        y_real: The list or series with the real classes
        y_pred: The list or series with the predicted classes

    Returns:
        tpr: The True Positive Rate of the classifier
        fpr: The False Positive Rate of the classifier
    '''

    # Calculates the confusion matrix and recover each element
    cm = confusion_matrix(y_real, y_pred)
    TN = cm[0, 0]
    FP = cm[0, 1]
    FN = cm[1, 0]
    TP = cm[1, 1]

    # Calculates tpr and fpr
    tpr =  TP/(TP + FN) # sensitivity - true positive rate
    fpr = 1 - TN/(TN+FP) # 1-specificity - false positive rate

    return tpr, fpr

def get_all_roc_coordinates(y_real, y_proba):
    '''
    Calculates all the ROC Curve coordinates (tpr and fpr) by considering each point as a threshold for the predicion of the class.

    Args:
        y_real: The list or series with the real classes.
        y_proba: The array with the probabilities for each class, obtained by using the `.predict_proba()` method.

    Returns:
        tpr_list: The list of TPRs representing each threshold.
        fpr_list: The list of FPRs representing each threshold.
    '''
    tpr_list = [0]
    fpr_list = [0]
    for i in range(len(y_proba)):
        threshold = y_proba[i]
        y_pred = y_proba >= threshold
        tpr, fpr = calculate_tpr_fpr(y_real, y_pred)
        tpr_list.append(tpr)
        fpr_list.append(fpr)
    return tpr_list, fpr_list


def plot_roc_curve(tpr, fpr, scatter = True, ax = None):
    '''
    Plots the ROC Curve by using the list of coordinates (tpr and fpr).

    Args:
        tpr: The list of TPRs representing each coordinate.
        fpr: The list of FPRs representing each coordinate.
        scatter: When True, the points used on the calculation will be plotted with the line (default = True).
    '''
    # if ax == None:
    #     plt.figure(figsize = (5, 5))
    #     ax = plt.axes()

    # if scatter:
    #     sns.scatterplot(x = fpr, y = tpr, ax = ax)
    # sns.lineplot(x = fpr, y = tpr, ax = ax)
    # sns.lineplot(x = [0, 1], y = [0, 1], color = 'green', ax = ax)
    # plt.xlim(-0.05, 1.05)
    # plt.ylim(-0.05, 1.05)
    # plt.xlabel("False Positive Rate")
    # plt.ylabel("True Positive Rate")

# plt.figure(figsize = (12, 8))
bins = [i/20 for i in range(20)] + [1]
classes = [0,1,2]
roc_auc_ovr = {}
for i in range(len(classes)):
    # Gets the class
    c = classes[i]

    # Prepares an auxiliar dataframe to help with the plots
    df_aux = df.copy()
    # df={}
    # print(classes[i],ytest[0])
    df_aux['class'] = [1 if y == c else 0 for y in ytest]
    df_aux['prob'] = np.array(newArray)[:, i]
    df_aux = df_aux.reset_index(drop = True)

    # Plots the probability distribution for the class and the rest
    # ax = plt.subplot(2, 3, i+1)
    # sns.histplot(x = "prob", data = df_aux, hue = 'class', color = 'b', ax = ax, bins = bins)
    # ax.set_title(c)
    # ax.legend([f"Class: {c}", "Rest"])
    # ax.set_xlabel(f"P(x = {c})")

    # Calculates the ROC Coordinates and plots the ROC Curves
    # ax_bottom = plt.subplot(2, 3, i+4)
    tpr, fpr = get_all_roc_coordinates(df_aux['class'], df_aux['prob'])
    # plot_roc_curve(tpr, fpr, scatter = False )
    # ax_bottom.set_title("ROC Curve OvR")

    # Calculates the ROC AUC OvR
    roc_auc_ovr[c] = roc_auc_score(df_aux['class'], df_aux['prob'])
# plt.tight_layout()


# Displays the ROC AUC for each class
avg_roc_auc = 0
i = 0
class_dict={0:'FA',1:'NIFTP', 2:'PTC'}
roc_auc_str=''
for k in roc_auc_ovr:
    avg_roc_auc += roc_auc_ovr[k]
    i += 1
    print(f"{k} ROC AUC OvR: {roc_auc_ovr[k]:.4f}")
    roc_auc_str=roc_auc_str+class_dict[k]+' - '+f"{roc_auc_ovr[k]:.4f}"+"  "

results_dict['Class-wise ROC_AUC_n score']=roc_auc_str
print(f"average ROC AUC OvR: {avg_roc_auc/i:.4f}")
results_dict['Average ROC_AUC_n score']=f"{avg_roc_auc/i:.4f}"
print(results_dict)



# Displays the ROC AUC for each class
avg_roc_auc = 0
i = 0
class_dict={0:'FA',1:'NIFTP', 2:'PTC'}
roc_auc_str=''
for k in roc_auc_ovr:
    avg_roc_auc += roc_auc_ovr[k]
    i += 1
    print(f"{k} ROC AUC OvR: {roc_auc_ovr[k]:.4f}")
    roc_auc_str=roc_auc_str+class_dict[k]+' - '+f"{roc_auc_ovr[k]:.4f}"+"  "

results_dict['Class-wise ROC_AUC_n score']=roc_auc_str
print(f"average ROC AUC OvR: {avg_roc_auc/i:.4f}")
results_dict['Average ROC_AUC_n score']=f"{avg_roc_auc/i:.4f}"

macro_roc_auc_func_n = roc_auc_score(ytest, newArray, labels = classes, multi_class = 'ovr', average = 'macro')
print('macro average roc_auc_n score from function - ', macro_roc_auc_func_n)
weighted_roc_auc_func_n = roc_auc_score(ytest, newArray, labels = classes, multi_class = 'ovr', average = 'weighted')
print('weighted average roc_auc_n score from function - ', weighted_roc_auc_func_n)
macro_ovo_roc_auc_func_n = roc_auc_score(ytest, newArray, labels = classes, multi_class = 'ovo', average = 'macro')
print('macro average ovo roc_auc_n score from function - ', macro_ovo_roc_auc_func_n)
weighted_ovo_roc_auc_func_n = roc_auc_score(ytest, newArray, labels = classes, multi_class = 'ovo', average = 'weighted')
print('weighted average ovo roc_auc score_n from function - ', weighted_ovo_roc_auc_func_n)

results_dict['Macro Average ROC_AUC_n score'] = macro_roc_auc_func_n
results_dict['Weighted Average ROC_AUC_n score'] = weighted_roc_auc_func_n
results_dict['Macro Average ovo ROC_AUC_n score'] = macro_roc_auc_func_n
results_dict['Weighted Average ovo ROC_AUC_n score'] = weighted_roc_auc_func_n

print(results_dict)


import pandas as pd
now= datetime.now()
dt_string = now.strftime("%d_%m_%Y %H_%M_%S")
results_df=pd.DataFrame(results_dict, index=[1])
results_df.to_excel('/workspace/storage/results/densenet/densenet_stacked_results'+dt_string+'.xlsx')

# ovo_roc_auc_func = roc_auc_score(ytest, prob, labels = classes, multi_class = 'ovo', average = None)
# print('ovo roc_auc score from function - ', macro_ovo_roc_auc_func)
# ovo_roc_auc_func_n = roc_auc_score(ytest, newArray, labels = classes, multi_class = 'ovo', average = None)
# print('ovo roc_auc score_n from function - ', weighted_ovo_roc_auc_func)

# results_dict['ovo ROC_AUC score'] = ovo_roc_auc_func
# results_dict['ovo ROC_AUC_n score'] = ovo_roc_auc_func_n
# results_df=pd.DataFrame(results_dict, index=[1])
# results_df.to_excel('/workspace/storage/results/densenet/densenet_capsule_results'+dt_string+'.xlsx')